# Orb 'circleci/gcp-gke@1.0.4' resolved to 'circleci/gcp-gke@1.0.4'
# Orb 'circleci/go@1.3.0' resolved to 'circleci/go@1.3.0'
version: 2
jobs:
  run_tests_custom_tokenizers:
    working_directory: ~/transformers
    docker:
    - image: circleci/python:3.7
    environment:
    - RUN_CUSTOM_TOKENIZERS: true
    - TRANSFORMERS_IS_CI: true
    steps:
    - checkout
    - restore_cache:
        keys:
        - v0.4-custom_tokenizers-{{ checksum "setup.py" }}
        - v0.4-{{ checksum "setup.py" }}
    - run:
        command: pip install --upgrade pip
    - run:
        command: pip install .[ja,testing,sentencepiece,jieba,spacy,ftfy]
    - run:
        command: python -m unidic download
    - save_cache:
        key: v0.4-custom_tokenizers-{{ checksum "setup.py" }}
        paths:
        - ~/.cache/pip
    - run:
        command: |
          if [ -f test_list.txt ]; then
            python -m pytest -s --make-reports=tests_custom_tokenizers ./tests/test_tokenization_bert_japanese.py ./tests/test_tokenization_openai.py | tee tests_output.txt
          fi
    - run:
        command: |
          if [ -f test_list.txt ]; then
            python -m pytest -n 1 tests/test_tokenization_clip.py --dist=loadfile -s --make-reports=tests_tokenization_clip --durations=100 | tee tests_output.txt
          fi
    - store_artifacts:
        path: ~/transformers/tests_output.txt
    - store_artifacts:
        path: ~/transformers/reports
  run_tests_onnxruntime_all:
    working_directory: ~/transformers
    docker:
    - image: circleci/python:3.7
    environment:
    - OMP_NUM_THREADS: 1
    - TRANSFORMERS_IS_CI: true
    resource_class: xlarge
    parallelism: 1
    steps:
    - checkout
    - restore_cache:
        keys:
        - v0.4-torch-{{ checksum "setup.py" }}
        - v0.4-{{ checksum "setup.py" }}
    - run:
        command: pip install --upgrade pip
    - run:
        command: pip install .[torch,testing,sentencepiece,onnxruntime]
    - save_cache:
        key: v0.4-onnx-{{ checksum "setup.py" }}
        paths:
        - ~/.cache/pip
    - run:
        command: |
          python -m pytest -n 1 --dist=loadfile -s --make-reports=tests_onnx tests -k onnx | tee tests_output.txt
    - store_artifacts:
        path: ~/transformers/tests_output.txt
    - store_artifacts:
        path: ~/transformers/reports
  run_tests_tf_all:
    working_directory: ~/transformers
    docker:
    - image: circleci/python:3.7
    environment:
    - OMP_NUM_THREADS: 1
    - TRANSFORMERS_IS_CI: true
    resource_class: xlarge
    parallelism: 1
    steps:
    - checkout
    - restore_cache:
        keys:
        - v0.4-tf-{{ checksum "setup.py" }}
        - v0.4-{{ checksum "setup.py" }}
    - run:
        command: sudo apt-get -y update && sudo apt-get install -y libsndfile1-dev espeak-ng
    - run:
        command: pip install --upgrade pip
    - run:
        command: pip install .[sklearn,tf-cpu,testing,sentencepiece,tf-speech,vision]
    - run:
        command: pip install tensorflow_probability
    - run:
        command: pip install https://github.com/kpu/kenlm/archive/master.zip
    - save_cache:
        key: v0.4-tf-{{ checksum "setup.py" }}
        paths:
        - ~/.cache/pip
    - run:
        command: |
          python -m pytest -n 8 --dist=loadfile -rA -s --make-reports=tests_tf tests | tee tests_output.txt
    - store_artifacts:
        path: ~/transformers/tests_output.txt
    - store_artifacts:
        path: ~/transformers/reports
  run_tests_torch_and_flax_all:
    working_directory: ~/transformers
    docker:
    - image: circleci/python:3.6
    environment:
    - OMP_NUM_THREADS: 1
    - RUN_PT_FLAX_CROSS_TESTS: true
    - TRANSFORMERS_IS_CI: true
    resource_class: xlarge
    parallelism: 1
    steps:
    - checkout
    - restore_cache:
        keys:
        - v0.4-torch_and_flax-{{ checksum "setup.py" }}
        - v0.4-{{ checksum "setup.py" }}
    - run:
        command: sudo apt-get -y update && sudo apt-get install -y libsndfile1-dev espeak-ng
    - run:
        command: pip install --upgrade pip
    - run:
        command: pip install .[sklearn,flax,torch,testing,sentencepiece,torch-speech,vision]
    - run:
        command: pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-1.10.0+cpu.html
    - run:
        command: pip install https://github.com/kpu/kenlm/archive/master.zip
    - save_cache:
        key: v0.4-{{ checksum "setup.py" }}
        paths:
        - ~/.cache/pip
    - run:
        command: |
          python -m pytest -n 8 --dist=loadfile -rA -s --make-reports=tests_torch_and_flax tests -m is_pt_flax_cross_test --durations=0 | tee tests_output.txt
    - store_artifacts:
        path: ~/transformers/tests_output.txt
    - store_artifacts:
        path: ~/transformers/reports
  run_tests_torch_and_tf:
    working_directory: ~/transformers
    docker:
    - image: circleci/python:3.7
    environment:
    - OMP_NUM_THREADS: 1
    - RUN_PT_TF_CROSS_TESTS: true
    - TRANSFORMERS_IS_CI: true
    resource_class: xlarge
    parallelism: 1
    steps:
    - checkout
    - restore_cache:
        keys:
        - v0.4-torch_and_tf-{{ checksum "setup.py" }}
        - v0.4-{{ checksum "setup.py" }}
    - run:
        command: sudo apt-get -y update && sudo apt-get install -y libsndfile1-dev espeak-ng
    - run:
        command: pip install --upgrade pip
    - run:
        command: pip install .[sklearn,tf-cpu,torch,testing,sentencepiece,torch-speech,vision]
    - run:
        command: pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-1.10.0+cpu.html
    - run:
        command: pip install tensorflow_probability
    - run:
        command: pip install https://github.com/kpu/kenlm/archive/master.zip
    - save_cache:
        key: v0.4-{{ checksum "setup.py" }}
        paths:
        - ~/.cache/pip
    - run:
        command: python utils/tests_fetcher.py | tee test_preparation.txt
    - store_artifacts:
        path: ~/transformers/test_preparation.txt
    - run:
        command: |
          if [ -f test_list.txt ]; then
            python -m pytest -n 8 --dist=loadfile -rA -s --make-reports=tests_torch_and_tf $(cat test_list.txt) -m is_pt_tf_cross_test --durations=0 | tee tests_output.txt
          fi
    - store_artifacts:
        path: ~/transformers/tests_output.txt
    - store_artifacts:
        path: ~/transformers/reports
  run_tests_flax:
    working_directory: ~/transformers
    docker:
    - image: circleci/python:3.7
    environment:
    - OMP_NUM_THREADS: 1
    - TRANSFORMERS_IS_CI: true
    resource_class: xlarge
    parallelism: 1
    steps:
    - checkout
    - restore_cache:
        keys:
        - v0.4-flax-{{ checksum "setup.py" }}
        - v0.4-{{ checksum "setup.py" }}
    - run:
        command: sudo apt-get -y update && sudo apt-get install -y libsndfile1-dev espeak-ng
    - run:
        command: pip install --upgrade pip
    - run:
        command: pip install .[flax,testing,sentencepiece,flax-speech,vision]
    - run:
        command: pip install https://github.com/kpu/kenlm/archive/master.zip
    - save_cache:
        key: v0.4-flax-{{ checksum "setup.py" }}
        paths:
        - ~/.cache/pip
    - run:
        command: python utils/tests_fetcher.py | tee test_preparation.txt
    - store_artifacts:
        path: ~/transformers/test_preparation.txt
    - run:
        command: |
          if [ -f test_list.txt ]; then
            python -m pytest -n 8 --dist=loadfile -rA -s --make-reports=tests_flax $(cat test_list.txt) | tee tests_output.txt
          fi
    - store_artifacts:
        path: ~/transformers/tests_output.txt
    - store_artifacts:
        path: ~/transformers/reports
  run_tests_torch:
    working_directory: ~/transformers
    docker:
    - image: circleci/python:3.7
    environment:
    - OMP_NUM_THREADS: 1
    - TRANSFORMERS_IS_CI: true
    resource_class: xlarge
    parallelism: 1
    steps:
    - checkout
    - restore_cache:
        keys:
        - v0.4-torch-{{ checksum "setup.py" }}
        - v0.4-{{ checksum "setup.py" }}
    - run:
        command: sudo apt-get -y update && sudo apt-get install -y libsndfile1-dev espeak-ng
    - run:
        command: pip install --upgrade pip
    - run:
        command: pip install .[sklearn,torch,testing,sentencepiece,torch-speech,vision,timm]
    - run:
        command: pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-1.10.0+cpu.html
    - run:
        command: pip install https://github.com/kpu/kenlm/archive/master.zip
    - save_cache:
        key: v0.4-torch-{{ checksum "setup.py" }}
        paths:
        - ~/.cache/pip
    - run:
        command: python utils/tests_fetcher.py | tee test_preparation.txt
    - store_artifacts:
        path: ~/transformers/test_preparation.txt
    - run:
        command: |
          if [ -f test_list.txt ]; then
            python -m pytest -n 3 --dist=loadfile -s --make-reports=tests_torch $(cat test_list.txt) | tee tests_output.txt
          fi
    - store_artifacts:
        path: ~/transformers/tests_output.txt
    - store_artifacts:
        path: ~/transformers/reports
  check_code_quality:
    working_directory: ~/transformers
    docker:
    - image: circleci/python:3.6
    resource_class: large
    environment:
    - TRANSFORMERS_IS_CI: true
    parallelism: 1
    steps:
    - checkout
    - restore_cache:
        keys:
        - v0.4-code_quality-{{ checksum "setup.py" }}
        - v0.4-{{ checksum "setup.py" }}
    - run:
        command: pip install --upgrade pip
    - run:
        command: pip install .[all,quality]
    - save_cache:
        key: v0.4-code_quality-{{ checksum "setup.py" }}
        paths:
        - ~/.cache/pip
    - run:
        command: black --check examples tests src utils
    - run:
        command: isort --check-only examples tests src utils
    - run:
        command: python utils/custom_init_isort.py --check_only
    - run:
        command: flake8 examples tests src utils
    - run:
        command: python utils/style_doc.py src/transformers docs/source --max_len 119 --check_only
  run_tests_tf:
    working_directory: ~/transformers
    docker:
    - image: circleci/python:3.7
    environment:
    - OMP_NUM_THREADS: 1
    - TRANSFORMERS_IS_CI: true
    resource_class: xlarge
    parallelism: 1
    steps:
    - checkout
    - restore_cache:
        keys:
        - v0.4-tf-{{ checksum "setup.py" }}
        - v0.4-{{ checksum "setup.py" }}
    - run:
        command: sudo apt-get -y update && sudo apt-get install -y libsndfile1-dev espeak-ng
    - run:
        command: pip install --upgrade pip
    - run:
        command: pip install .[sklearn,tf-cpu,testing,sentencepiece,tf-speech,vision]
    - run:
        command: pip install tensorflow_probability
    - run:
        command: pip install https://github.com/kpu/kenlm/archive/master.zip
    - save_cache:
        key: v0.4-tf-{{ checksum "setup.py" }}
        paths:
        - ~/.cache/pip
    - run:
        command: python utils/tests_fetcher.py | tee test_preparation.txt
    - store_artifacts:
        path: ~/transformers/test_preparation.txt
    - run:
        command: |
          if [ -f test_list.txt ]; then
            python -m pytest -n 8 --dist=loadfile -rA -s --make-reports=tests_tf $(cat test_list.txt) | tee tests_output.txt
          fi
    - store_artifacts:
        path: ~/transformers/tests_output.txt
    - store_artifacts:
        path: ~/transformers/reports
  run_tests_hub_all:
    working_directory: ~/transformers
    docker:
    - image: circleci/python:3.7
    environment:
    - HUGGINGFACE_CO_STAGING: true
    - RUN_GIT_LFS_TESTS: true
    - TRANSFORMERS_IS_CI: true
    resource_class: xlarge
    parallelism: 1
    steps:
    - checkout
    - restore_cache:
        keys:
        - v0.4-hub-{{ checksum "setup.py" }}
        - v0.4-{{ checksum "setup.py" }}
    - run:
        command: sudo apt-get install git-lfs
    - run:
        command: |
          git config --global user.email "ci@dummy.com"
          git config --global user.name "ci"
    - run:
        command: pip install --upgrade pip
    - run:
        command: pip install .[torch,sentencepiece,testing]
    - save_cache:
        key: v0.4-hub-{{ checksum "setup.py" }}
        paths:
        - ~/.cache/pip
    - run:
        command: |
          python -m pytest -sv --make-reports=tests_hub tests -m is_staging_test | tee tests_output.txt
    - store_artifacts:
        path: ~/transformers/tests_output.txt
    - store_artifacts:
        path: ~/transformers/reports
  run_tests_torch_and_flax:
    working_directory: ~/transformers
    docker:
    - image: circleci/python:3.6
    environment:
    - OMP_NUM_THREADS: 1
    - RUN_PT_FLAX_CROSS_TESTS: true
    - TRANSFORMERS_IS_CI: true
    resource_class: xlarge
    parallelism: 1
    steps:
    - checkout
    - restore_cache:
        keys:
        - v0.4-torch_and_flax-{{ checksum "setup.py" }}
        - v0.4-{{ checksum "setup.py" }}
    - run:
        command: sudo apt-get -y update && sudo apt-get install -y libsndfile1-dev espeak-ng
    - run:
        command: pip install --upgrade pip
    - run:
        command: pip install .[sklearn,flax,torch,testing,sentencepiece,torch-speech,vision]
    - run:
        command: pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-1.10.0+cpu.html
    - run:
        command: pip install https://github.com/kpu/kenlm/archive/master.zip
    - save_cache:
        key: v0.4-{{ checksum "setup.py" }}
        paths:
        - ~/.cache/pip
    - run:
        command: python utils/tests_fetcher.py | tee test_preparation.txt
    - store_artifacts:
        path: ~/transformers/test_preparation.txt
    - run:
        command: |
          if [ -f test_list.txt ]; then
            python -m pytest -n 8 --dist=loadfile -rA -s --make-reports=tests_torch_and_flax $(cat test_list.txt) -m is_pt_flax_cross_test --durations=0 | tee tests_output.txt
          fi
    - store_artifacts:
        path: ~/transformers/tests_output.txt
    - store_artifacts:
        path: ~/transformers/reports
  run_tests_torch_and_tf_all:
    working_directory: ~/transformers
    docker:
    - image: circleci/python:3.7
    environment:
    - OMP_NUM_THREADS: 1
    - RUN_PT_TF_CROSS_TESTS: true
    - TRANSFORMERS_IS_CI: true
    resource_class: xlarge
    parallelism: 1
    steps:
    - checkout
    - restore_cache:
        keys:
        - v0.4-torch_and_tf-{{ checksum "setup.py" }}
        - v0.4-{{ checksum "setup.py" }}
    - run:
        command: sudo apt-get -y update && sudo apt-get install -y libsndfile1-dev espeak-ng
    - run:
        command: pip install --upgrade pip
    - run:
        command: pip install .[sklearn,tf-cpu,torch,testing,sentencepiece,torch-speech,vision]
    - run:
        command: pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-1.10.0+cpu.html
    - run:
        command: pip install tensorflow_probability
    - run:
        command: pip install https://github.com/kpu/kenlm/archive/master.zip
    - save_cache:
        key: v0.4-{{ checksum "setup.py" }}
        paths:
        - ~/.cache/pip
    - run:
        command: |
          python -m pytest -n 8 --dist=loadfile -rA -s --make-reports=tests_torch_and_tf tests -m is_pt_tf_cross_test --durations=0 | tee tests_output.txt
    - store_artifacts:
        path: ~/transformers/tests_output.txt
    - store_artifacts:
        path: ~/transformers/reports
  run_tests_pipelines_torch_all:
    working_directory: ~/transformers
    docker:
    - image: circleci/python:3.7
    environment:
    - OMP_NUM_THREADS: 1
    - RUN_PIPELINE_TESTS: true
    - TRANSFORMERS_IS_CI: true
    resource_class: xlarge
    parallelism: 1
    steps:
    - checkout
    - restore_cache:
        keys:
        - v0.4-torch-{{ checksum "setup.py" }}
        - v0.4-{{ checksum "setup.py" }}
    - run:
        command: sudo apt-get -y update && sudo apt-get install -y libsndfile1-dev espeak-ng
    - run:
        command: pip install --upgrade pip
    - run:
        command: pip install .[sklearn,torch,testing,sentencepiece,torch-speech,vision,timm]
    - run:
        command: pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-1.10.0+cpu.html
    - run:
        command: pip install https://github.com/kpu/kenlm/archive/master.zip
    - save_cache:
        key: v0.4-torch-{{ checksum "setup.py" }}
        paths:
        - ~/.cache/pip
    - run:
        command: |
          python -m pytest -n 8 --dist=loadfile -rA -s --make-reports=tests_pipelines_torch -m is_pipeline_test tests | tee tests_output.txt
    - store_artifacts:
        path: ~/transformers/tests_output.txt
    - store_artifacts:
        path: ~/transformers/reports
  check_repository_consistency:
    working_directory: ~/transformers
    docker:
    - image: circleci/python:3.6
    resource_class: large
    environment:
    - TRANSFORMERS_IS_CI: true
    parallelism: 1
    steps:
    - checkout
    - restore_cache:
        keys:
        - v0.4-repository_consistency-{{ checksum "setup.py" }}
        - v0.4-{{ checksum "setup.py" }}
    - run:
        command: pip install --upgrade pip
    - run:
        command: pip install .[all,quality]
    - save_cache:
        key: v0.4-repository_consistency-{{ checksum "setup.py" }}
        paths:
        - ~/.cache/pip
    - run:
        command: python utils/check_copies.py
    - run:
        command: python utils/check_table.py
    - run:
        command: python utils/check_dummies.py
    - run:
        command: python utils/check_repo.py
    - run:
        command: python utils/check_inits.py
    - run:
        command: make deps_table_check_updated
    - run:
        command: python utils/tests_fetcher.py --sanity_check
  run_examples_torch:
    working_directory: ~/transformers
    docker:
    - image: circleci/python:3.6
    environment:
    - OMP_NUM_THREADS: 1
    - TRANSFORMERS_IS_CI: true
    resource_class: xlarge
    parallelism: 1
    steps:
    - checkout
    - restore_cache:
        keys:
        - v0.4-torch_examples-{{ checksum "setup.py" }}
        - v0.4-{{ checksum "setup.py" }}
    - run:
        command: sudo apt-get -y update && sudo apt-get install -y libsndfile1-dev espeak-ng
    - run:
        command: pip install --upgrade pip
    - run:
        command: pip install .[sklearn,torch,sentencepiece,testing,torch-speech]
    - run:
        command: pip install -r examples/pytorch/_tests_requirements.txt
    - save_cache:
        key: v0.4-torch_examples-{{ checksum "setup.py" }}
        paths:
        - ~/.cache/pip
    - run:
        command: python utils/tests_fetcher.py --filters examples tests | tee test_preparation.txt
    - store_artifacts:
        path: ~/transformers/test_preparation.txt
    - run:
        command: |
          if [ -f test_list.txt ]; then
            python -m pytest -n 8 --dist=loadfile -s --make-reports=examples_torch ./examples/pytorch/ | tee tests_output.txt
          fi
    - store_artifacts:
        path: ~/transformers/examples_output.txt
    - store_artifacts:
        path: ~/transformers/reports
  run_tests_layoutlmv2:
    working_directory: ~/transformers
    docker:
    - image: circleci/python:3.7
    environment:
    - OMP_NUM_THREADS: 1
    - TRANSFORMERS_IS_CI: true
    resource_class: xlarge
    parallelism: 1
    steps:
    - checkout
    - restore_cache:
        keys:
        - v0.4-torch-{{ checksum "setup.py" }}
        - v0.4-{{ checksum "setup.py" }}
    - run:
        command: sudo apt-get -y update && sudo apt-get install -y libsndfile1-dev
    - run:
        command: pip install --upgrade pip
    - run:
        command: pip install .[torch,testing,vision]
    - run:
        command: pip install torchvision
    - run:
        command: python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'
    - run:
        command: sudo apt install tesseract-ocr
    - run:
        command: pip install pytesseract
    - save_cache:
        key: v0.4-torch-{{ checksum "setup.py" }}
        paths:
        - ~/.cache/pip
    - run:
        command: python utils/tests_fetcher.py | tee test_preparation.txt
    - store_artifacts:
        path: ~/transformers/test_preparation.txt
    - run:
        command: |
          if [ -f test_list.txt ]; then
            python -m pytest -n 1 tests/*layoutlmv2* --dist=loadfile -s --make-reports=tests_layoutlmv2 --durations=100
          fi
    - store_artifacts:
        path: ~/transformers/tests_output.txt
    - store_artifacts:
        path: ~/transformers/reports
  run_examples_torch_all:
    working_directory: ~/transformers
    docker:
    - image: circleci/python:3.6
    environment:
    - OMP_NUM_THREADS: 1
    - TRANSFORMERS_IS_CI: true
    resource_class: xlarge
    parallelism: 1
    steps:
    - checkout
    - restore_cache:
        keys:
        - v0.4-torch_examples-{{ checksum "setup.py" }}
        - v0.4-{{ checksum "setup.py" }}
    - run:
        command: sudo apt-get -y update && sudo apt-get install -y libsndfile1-dev espeak-ng
    - run:
        command: pip install --upgrade pip
    - run:
        command: pip install .[sklearn,torch,sentencepiece,testing,torch-speech]
    - run:
        command: pip install -r examples/pytorch/_tests_requirements.txt
    - save_cache:
        key: v0.4-torch_examples-{{ checksum "setup.py" }}
        paths:
        - ~/.cache/pip
    - run:
        command: |
          TRANSFORMERS_IS_CI=1 python -m pytest -n 8 --dist=loadfile -s --make-reports=examples_torch ./examples/pytorch/ | tee examples_output.txt
    - store_artifacts:
        path: ~/transformers/examples_output.txt
    - store_artifacts:
        path: ~/transformers/reports
  run_examples_flax_all:
    working_directory: ~/transformers
    docker:
    - image: circleci/python:3.7
    environment:
    - OMP_NUM_THREADS: 1
    - TRANSFORMERS_IS_CI: true
    resource_class: xlarge
    parallelism: 1
    steps:
    - checkout
    - restore_cache:
        keys:
        - v0.4-flax_examples-{{ checksum "setup.py" }}
        - v0.4-{{ checksum "setup.py" }}
    - run:
        command: pip install --upgrade pip
    - run:
        command: sudo pip install .[flax,testing,sentencepiece]
    - run:
        command: pip install -r examples/flax/_tests_requirements.txt
    - save_cache:
        key: v0.4-flax_examples-{{ checksum "setup.py" }}
        paths:
        - ~/.cache/pip
    - run:
        command: |
          TRANSFORMERS_IS_CI=1 python -m pytest -n 8 --dist=loadfile -s --make-reports=examples_flax ./examples/flax/ | tee examples_output.txt
    - store_artifacts:
        path: ~/transformers/flax_examples_output.txt
    - store_artifacts:
        path: ~/transformers/reports
  run_examples_flax:
    working_directory: ~/transformers
    docker:
    - image: circleci/python:3.7
    environment:
    - OMP_NUM_THREADS: 1
    - TRANSFORMERS_IS_CI: true
    resource_class: xlarge
    parallelism: 1
    steps:
    - checkout
    - restore_cache:
        keys:
        - v0.4-flax_examples-{{ checksum "setup.py" }}
        - v0.4-{{ checksum "setup.py" }}
    - run:
        command: pip install --upgrade pip
    - run:
        command: sudo pip install .[flax,testing,sentencepiece]
    - run:
        command: pip install -r examples/flax/_tests_requirements.txt
    - save_cache:
        key: v0.4-flax_examples-{{ checksum "setup.py" }}
        paths:
        - ~/.cache/pip
    - run:
        command: python utils/tests_fetcher.py --filters examples tests | tee test_preparation.txt
    - store_artifacts:
        path: ~/transformers/test_preparation.txt
    - run:
        command: |
          if [ -f test_list.txt ]; then
            python -m pytest -n 8 --dist=loadfile -s --make-reports=examples_flax ./examples/flax/ | tee tests_output.txt
          fi
    - store_artifacts:
        path: ~/transformers/flax_examples_output.txt
    - store_artifacts:
        path: ~/transformers/reports
  run_tests_pipelines_tf_all:
    working_directory: ~/transformers
    docker:
    - image: circleci/python:3.7
    environment:
    - OMP_NUM_THREADS: 1
    - RUN_PIPELINE_TESTS: true
    - TRANSFORMERS_IS_CI: true
    resource_class: xlarge
    parallelism: 1
    steps:
    - checkout
    - restore_cache:
        keys:
        - v0.4-tf-{{ checksum "setup.py" }}
        - v0.4-{{ checksum "setup.py" }}
    - run:
        command: pip install --upgrade pip
    - run:
        command: pip install .[sklearn,tf-cpu,testing,sentencepiece]
    - run:
        command: pip install tensorflow_probability
    - save_cache:
        key: v0.4-tf-{{ checksum "setup.py" }}
        paths:
        - ~/.cache/pip
    - run:
        command: |
          python -m pytest -n 8 --dist=loadfile -rA -s --make-reports=tests_pipelines_tf tests -m is_pipeline_test | tee tests_output.txt
    - store_artifacts:
        path: ~/transformers/tests_output.txt
    - store_artifacts:
        path: ~/transformers/reports
  run_tests_hub:
    working_directory: ~/transformers
    docker:
    - image: circleci/python:3.7
    environment:
    - HUGGINGFACE_CO_STAGING: true
    - RUN_GIT_LFS_TESTS: true
    - TRANSFORMERS_IS_CI: true
    resource_class: xlarge
    parallelism: 1
    steps:
    - checkout
    - restore_cache:
        keys:
        - v0.4-hub-{{ checksum "setup.py" }}
        - v0.4-{{ checksum "setup.py" }}
    - run:
        command: sudo apt-get install git-lfs
    - run:
        command: |
          git config --global user.email "ci@dummy.com"
          git config --global user.name "ci"
    - run:
        command: pip install --upgrade pip
    - run:
        command: pip install .[torch,sentencepiece,testing]
    - save_cache:
        key: v0.4-hub-{{ checksum "setup.py" }}
        paths:
        - ~/.cache/pip
    - run:
        command: python utils/tests_fetcher.py | tee test_preparation.txt
    - store_artifacts:
        path: ~/transformers/test_preparation.txt
    - run:
        command: |
          if [ -f test_list.txt ]; then
            python -m pytest -sv --make-reports=tests_hub $(cat test_list.txt) -m is_staging_test | tee tests_output.txt
          fi
    - store_artifacts:
        path: ~/transformers/tests_output.txt
    - store_artifacts:
        path: ~/transformers/reports
  run_tests_onnxruntime:
    working_directory: ~/transformers
    docker:
    - image: circleci/python:3.7
    environment:
    - OMP_NUM_THREADS: 1
    - TRANSFORMERS_IS_CI: true
    resource_class: xlarge
    parallelism: 1
    steps:
    - checkout
    - restore_cache:
        keys:
        - v0.4-torch-{{ checksum "setup.py" }}
        - v0.4-{{ checksum "setup.py" }}
    - run:
        command: pip install --upgrade pip
    - run:
        command: pip install .[torch,testing,sentencepiece,onnxruntime]
    - save_cache:
        key: v0.4-onnx-{{ checksum "setup.py" }}
        paths:
        - ~/.cache/pip
    - run:
        command: python utils/tests_fetcher.py | tee test_preparation.txt
    - store_artifacts:
        path: ~/transformers/test_preparation.txt
    - run:
        command: |
          if [ -f test_list.txt ]; then
            python -m pytest -n 1 --dist=loadfile -s --make-reports=tests_onnx $(cat test_list.txt) -k onnx | tee tests_output.txt
          fi
    - store_artifacts:
        path: ~/transformers/tests_output.txt
    - store_artifacts:
        path: ~/transformers/reports
  run_tests_torch_all:
    working_directory: ~/transformers
    docker:
    - image: circleci/python:3.7
    environment:
    - OMP_NUM_THREADS: 1
    - TRANSFORMERS_IS_CI: true
    resource_class: xlarge
    parallelism: 1
    steps:
    - checkout
    - restore_cache:
        keys:
        - v0.4-torch-{{ checksum "setup.py" }}
        - v0.4-{{ checksum "setup.py" }}
    - run:
        command: sudo apt-get -y update && sudo apt-get install -y libsndfile1-dev espeak-ng
    - run:
        command: pip install --upgrade pip
    - run:
        command: pip install .[sklearn,torch,testing,sentencepiece,torch-speech,vision,timm]
    - run:
        command: pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-1.10.0+cpu.html
    - run:
        command: pip install https://github.com/kpu/kenlm/archive/master.zip
    - save_cache:
        key: v0.4-torch-{{ checksum "setup.py" }}
        paths:
        - ~/.cache/pip
    - run:
        command: |
          python -m pytest -n 3 --dist=loadfile -s --make-reports=tests_torch tests | tee tests_output.txt
    - store_artifacts:
        path: ~/transformers/tests_output.txt
    - store_artifacts:
        path: ~/transformers/reports
  run_tests_pipelines_tf:
    working_directory: ~/transformers
    docker:
    - image: circleci/python:3.7
    environment:
    - OMP_NUM_THREADS: 1
    - RUN_PIPELINE_TESTS: true
    - TRANSFORMERS_IS_CI: true
    resource_class: xlarge
    parallelism: 1
    steps:
    - checkout
    - restore_cache:
        keys:
        - v0.4-tf-{{ checksum "setup.py" }}
        - v0.4-{{ checksum "setup.py" }}
    - run:
        command: pip install --upgrade pip
    - run:
        command: pip install .[sklearn,tf-cpu,testing,sentencepiece]
    - run:
        command: pip install tensorflow_probability
    - save_cache:
        key: v0.4-tf-{{ checksum "setup.py" }}
        paths:
        - ~/.cache/pip
    - run:
        command: python utils/tests_fetcher.py | tee test_preparation.txt
    - store_artifacts:
        path: ~/transformers/test_preparation.txt
    - run:
        command: |
          if [ -f test_list.txt ]; then
            python -m pytest -n 8 --dist=loadfile -rA -s --make-reports=tests_pipelines_tf $(cat test_list.txt) -m is_pipeline_test | tee tests_output.txt
          fi
    - store_artifacts:
        path: ~/transformers/tests_output.txt
    - store_artifacts:
        path: ~/transformers/reports
  run_tests_pipelines_torch:
    working_directory: ~/transformers
    docker:
    - image: circleci/python:3.7
    environment:
    - OMP_NUM_THREADS: 1
    - RUN_PIPELINE_TESTS: true
    - TRANSFORMERS_IS_CI: true
    resource_class: xlarge
    parallelism: 1
    steps:
    - checkout
    - restore_cache:
        keys:
        - v0.4-torch-{{ checksum "setup.py" }}
        - v0.4-{{ checksum "setup.py" }}
    - run:
        command: sudo apt-get -y update && sudo apt-get install -y libsndfile1-dev espeak-ng
    - run:
        command: pip install --upgrade pip
    - run:
        command: pip install .[sklearn,torch,testing,sentencepiece,torch-speech,vision,timm]
    - run:
        command: pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-1.10.0+cpu.html
    - run:
        command: pip install https://github.com/kpu/kenlm/archive/master.zip
    - save_cache:
        key: v0.4-torch-{{ checksum "setup.py" }}
        paths:
        - ~/.cache/pip
    - run:
        command: python utils/tests_fetcher.py | tee test_preparation.txt
    - store_artifacts:
        path: ~/transformers/test_preparation.txt
    - run:
        command: |
          if [ -f test_list.txt ]; then
            python -m pytest -n 8 --dist=loadfile -rA -s --make-reports=tests_pipelines_torch -m is_pipeline_test $(cat test_list.txt) | tee tests_output.txt
          fi
    - store_artifacts:
        path: ~/transformers/tests_output.txt
    - store_artifacts:
        path: ~/transformers/reports
  run_tests_flax_all:
    working_directory: ~/transformers
    docker:
    - image: circleci/python:3.7
    environment:
    - OMP_NUM_THREADS: 1
    - TRANSFORMERS_IS_CI: true
    resource_class: xlarge
    parallelism: 1
    steps:
    - checkout
    - restore_cache:
        keys:
        - v0.4-flax-{{ checksum "setup.py" }}
        - v0.4-{{ checksum "setup.py" }}
    - run:
        command: sudo apt-get -y update && sudo apt-get install -y libsndfile1-dev espeak-ng
    - run:
        command: pip install --upgrade pip
    - run:
        command: pip install .[flax,testing,sentencepiece,vision,flax-speech]
    - run:
        command: pip install https://github.com/kpu/kenlm/archive/master.zip
    - save_cache:
        key: v0.4-flax-{{ checksum "setup.py" }}
        paths:
        - ~/.cache/pip
    - run:
        command: |
          python -m pytest -n 8 --dist=loadfile -rA -s --make-reports=tests_flax tests | tee tests_output.txt
    - store_artifacts:
        path: ~/transformers/tests_output.txt
    - store_artifacts:
        path: ~/transformers/reports
workflows:
  version: 2
  build_and_test:
    jobs:
    - check_code_quality
    - check_repository_consistency
    - run_examples_torch
    - run_examples_flax
    - run_tests_custom_tokenizers
    - run_tests_torch_and_tf
    - run_tests_torch_and_flax
    - run_tests_torch
    - run_tests_tf
    - run_tests_flax
    - run_tests_pipelines_torch
    - run_tests_pipelines_tf
    - run_tests_onnxruntime
    - run_tests_hub
    - run_tests_layoutlmv2
  nightly:
    triggers:
    - schedule:
        cron: 0 0 * * *
        filters:
          branches:
            only:
            - master
    jobs:
    - run_examples_torch_all
    - run_examples_flax_all
    - run_tests_torch_and_tf_all
    - run_tests_torch_and_flax_all
    - run_tests_torch_all
    - run_tests_tf_all
    - run_tests_flax_all
    - run_tests_pipelines_torch_all
    - run_tests_pipelines_tf_all
    - run_tests_onnxruntime_all
    - run_tests_hub_all
